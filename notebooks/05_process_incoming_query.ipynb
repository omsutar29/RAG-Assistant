{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87079271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to install scikit-learn and LLM in Colab.\n",
    "!pip install scikit-learn\n",
    "!pip install -q transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load data\n",
    "df = joblib.load(\"embeddings.joblib\")\n",
    "df[\"embedding\"] = df[\"embedding\"].apply(np.array)\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "def create_embedding(text_list):\n",
    "    return embedding_model.encode(text_list, normalize_embeddings=True)\n",
    "\n",
    "# Load LLM once\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "def inference(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    encoded = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        encoded,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    resp = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    if \"assistant\" in resp:\n",
    "        return resp.split(\"assistant\")[-1].strip()\n",
    "    return resp.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cdf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_query = input(\"Ask a Question: \")\n",
    "\n",
    "question_embedding = create_embedding([incoming_query])[0]\n",
    "similarities = cosine_similarity(\n",
    "    np.vstack(df[\"embedding\"].to_numpy()), \n",
    "    [question_embedding]\n",
    ").flatten()\n",
    "max_indx = similarities.argsort()[::-1][:5]\n",
    "\n",
    "max_similarity = similarities[max_indx[0]]\n",
    "RELEVANCE_THRESHOLD = 0.3\n",
    "\n",
    "if max_similarity < RELEVANCE_THRESHOLD:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {incoming_query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    print(\"Answer:\\nI couldn't find any relevant information about this topic in the course materials. This question appears to be outside the scope of this course.\")\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "else:\n",
    "    new_df = df.loc[max_indx]\n",
    "    \n",
    "    context_text = \"\"\n",
    "    for idx, row in new_df.iterrows():\n",
    "        context_text += f\"\\n[Video #{row['number']}: {row['title']}]\\n\"\n",
    "        context_text += f\"Timestamp: {row['start']}s - {row['end']}s\\n\"\n",
    "        context_text += f\"Content: {row['text']}\\n\"\n",
    "    \n",
    "    relevance_check_prompt = f\"\"\"Question: {incoming_query}\n",
    "\n",
    "Course content:\n",
    "{context_text}\n",
    "\n",
    "Is this question answerable using the course content above? Answer only \"YES\" or \"NO\".\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    relevance_response = inference(relevance_check_prompt).strip().upper()\n",
    "    \n",
    "    if \"NO\" in relevance_response or \"NOT\" in relevance_response:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Question: {incoming_query}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        print(\"Answer:\\nI couldn't find any relevant information about this topic in the course materials. This question appears to be outside the scope of this course.\")\n",
    "        print(f\"\\n{'='*60}\\n\")\n",
    "    else:\n",
    "        \n",
    "        prompt = f\"\"\"Question: {incoming_query}\n",
    "\n",
    "Here are relevant video segments from the course:\n",
    "{context_text}\n",
    "\n",
    "Answer the question by listing the videos where this topic is covered. Use this exact format for each video:\n",
    "\n",
    "- Video #[number] ([title]) at [start]s-[end]s: [brief description]\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        response = inference(prompt)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Question: {incoming_query}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        print(f\"Answer:\\n{response}\")\n",
    "        print(f\"\\n{'='*60}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
